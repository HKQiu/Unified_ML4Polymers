{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/work/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-01 20:30:53.347227: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-01 20:30:53.405450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 20:30:54.184675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, T5Config, T5ForConditionalGeneration\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# 类\n",
    "\n",
    "class GPT2Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, propmt_list, answer_list, tokenizer,\n",
    "               max_length_propmt=1024, max_length_answer=10):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_ids = []\n",
    "    self.attn_masks = []\n",
    "    self.answer_ids = []\n",
    "\n",
    "    # 设置填充参数为右填充\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    for txt in propmt_list:\n",
    "\n",
    "      encodings_dict = tokenizer('<s>'+ txt , truncation=True, max_length=max_length_propmt, padding=\"max_length\")\n",
    "\n",
    "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "    for ans in answer_list:\n",
    "\n",
    "      encodings_dict = tokenizer('<s>'+ str(ans), truncation=True, max_length=max_length_answer, padding=\"max_length\")\n",
    "\n",
    "      self.answer_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.attn_masks[idx], self.answer_ids[idx]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(config_path, model_path, tokenizer, train_dataloader,\n",
    "                   validation_dataloader,epochs,learning_rate,warmup_ratio,\n",
    "                   epsilon):\n",
    "    # I'm not really doing anything with the config buheret\n",
    "    configuration = T5Config.from_pretrained(config_path, output_hidden_states=False)\n",
    "\n",
    "    # instantiate the model\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path, config=configuration)\n",
    "\n",
    "    # this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "    # otherwise the tokenizer and model tensors won't match up\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        # Wrap the model with DataParallel to use both GPUs\n",
    "        model = DataParallel(model)\n",
    "\n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    # some parameters I cooked up that work reasonably well\n",
    "\n",
    "    epochs = epochs\n",
    "    learning_rate = learning_rate\n",
    "    warmup_steps = int(len(train_dataloader) * epochs * warmup_ratio)\n",
    "    epsilon = epsilon\n",
    "\n",
    "    # this produces sample output every 100 steps\n",
    "    sample_every = 1000\n",
    "\n",
    "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                    lr = learning_rate,\n",
    "                    eps = epsilon\n",
    "                    )\n",
    "\n",
    "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Create the learning rate scheduler.\n",
    "    # This changes the learning rate as the training loop progresses\n",
    "    # scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "    #                                             num_warmup_steps = warmup_steps, \n",
    "    #                                             num_training_steps = total_steps)\n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    \n",
    "    def format_time(elapsed):\n",
    "        return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
    "\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        total_train_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            b_masks = batch[1].to(device)\n",
    "\n",
    "            model.zero_grad()        \n",
    "\n",
    "            outputs = model(  b_input_ids,\n",
    "                            labels=b_labels, \n",
    "                            attention_mask = b_masks,\n",
    "                            output_attentions=True\n",
    "                            )\n",
    "\n",
    "            loss = outputs[0]  \n",
    "            loss = loss.mean()  # 获取所有GPU上的平均损失\n",
    "\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            total_train_loss += batch_loss\n",
    "\n",
    "            # Get sample every x batches.\n",
    "            if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader) \n",
    "        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch_i+1)      \n",
    "        \n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "            \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_loss = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "            \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            b_masks = batch[1].to(device)\n",
    "            \n",
    "            with torch.no_grad():        \n",
    "                outputs  = model(b_input_ids, \n",
    "    #                            token_type_ids=None, \n",
    "                                attention_mask = b_masks,\n",
    "                                labels=b_labels,\n",
    "                                output_attentions=True)\n",
    "            \n",
    "                loss = outputs[0]  \n",
    "                loss = loss.mean()  # 获取所有GPU上的平均损失\n",
    "            batch_loss = loss.item()\n",
    "            total_eval_loss += batch_loss        \n",
    "\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        writer.add_scalar(\"Loss/test\", avg_val_loss, epoch_i+1)\n",
    "        \n",
    "        validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "    return model, tokenizer, training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/tmp/ipykernel_28935/66796037.py:39: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(doc_lengths)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_path = 'seyonec/PubChem10M_SMILES_BPE_450k'\n",
    "path = 'GT4SD/multitask-text-and-chemistry-t5-base-standard'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(token_path, bos_token='<s>', eos_token='</s>', pad_token='[PAD]', padding_side='right') \n",
    "# print(\"The max model length is {} for this model.\".format(tokenizer.model_max_length))\n",
    "# print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "# print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "# print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))\n",
    "custom_tokens = [\n",
    "    'Predict the atomization energy of the following SMILES:',\n",
    "    'Predict the bandgap crystal of the following SMILES:',\n",
    "    'Predict the Tg of the following SMILES:',\n",
    "    'Predict the heat resistance class of the following SMILES:'\n",
    "]\n",
    "tokenizer.add_tokens(custom_tokens)\n",
    "\n",
    "df_train = pd.read_csv('/work/PolyGPT/T5/0data&code/data/train/prompt-target.csv')\n",
    "df_train.dropna(inplace=True) #remove NA values\n",
    "prompt_list_train = df_train['prompt'].tolist() #just use the main bio text in this example\n",
    "answer_list_train = df_train['target'].tolist() #just use the main bio text in this example\n",
    "\n",
    "df_test = pd.read_csv('/work/PolyGPT/T5/0data&code/data/test/prompt-target.csv')\n",
    "df_test.dropna(inplace=True) #remove NA values\n",
    "prompt_list_test = df_test['prompt'].tolist() #just use the main bio text in this example\n",
    "answer_list_test = df_test['target'].tolist() #just use the main bio text in this example\n",
    "\n",
    "doc_lengths = []\n",
    "\n",
    "for prompt in prompt_list_test:\n",
    "\n",
    "    # get rough token count distribution\n",
    "    # tokens = nltk.word_tokenize(bio)\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "\n",
    "    doc_lengths.append(len(tokens))\n",
    "\n",
    "doc_lengths = np.array(doc_lengths)\n",
    "\n",
    "sns.distplot(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,650 training samples\n",
      "2,320 validation samples\n",
      "Let's use 2 GPUs!\n",
      "\n",
      "======== Epoch 1 / 100 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/work/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/anaconda3/envs/work/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 7.89\n",
      "  Training epoch took: 0:02:03\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 6.89\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 2 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 6.96\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 5.86\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 3 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 6.16\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 5.28\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 4 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 5.58\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 4.75\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 5 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 5.11\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 4.31\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 6 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 4.69\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 3.90\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 7 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 4.27\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 3.45\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 8 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.83\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.96\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 9 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 3.36\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.50\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 10 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.96\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.22\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 11 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.65\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 2.01\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 12 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.43\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.85\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 13 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.25\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.73\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 14 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.11\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.64\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 15 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.00\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.59\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 16 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.90\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.53\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 17 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.83\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.49\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 18 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.76\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.45\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 19 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.71\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.41\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 20 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.65\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.38\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 21 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.61\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.35\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 22 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.57\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.32\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 23 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.53\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.30\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 24 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.50\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.29\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 25 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.47\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.27\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 26 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.25\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 27 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.41\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.24\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 28 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.39\n",
      "  Training epoch took: 0:02:01\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.23\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 29 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.37\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.22\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 30 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.35\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.20\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 31 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.33\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.20\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 32 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.32\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.19\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 33 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.30\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.18\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 34 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.28\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.18\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 35 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.27\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.17\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 36 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.17\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 37 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.17\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 38 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.23\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.16\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 39 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.16\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 40 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.21\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.16\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 41 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.20\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.15\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 42 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.19\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.15\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 43 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.15\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 44 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.17\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.15\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 45 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.16\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.15\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 46 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 47 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.15\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 48 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.14\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 49 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 50 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.13\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 51 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.12\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 52 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 53 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.11\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 54 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 55 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 56 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.10\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 57 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.09\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 58 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 59 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 60 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.08\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 61 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 62 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 63 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 64 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.07\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 65 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 66 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 67 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 68 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.06\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 69 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 70 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 71 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 72 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.05\n",
      "  Training epoch took: 0:01:58\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 73 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 74 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 75 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 76 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 77 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:02:00\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 78 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 79 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 80 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 81 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 82 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 83 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 84 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 85 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 86 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 87 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 88 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 89 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 90 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 91 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 92 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 93 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 94 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 95 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 96 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 97 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 98 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 99 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.02\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "======== Epoch 100 / 100 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.03\n",
      "  Training epoch took: 0:01:59\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.13\n",
      "  Validation took: 0:00:07\n",
      "\n",
      "Training complete!\n",
      "Total training took 3:30:17 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "## fine tune on properties datasets\n",
    "batch_size = 120\n",
    "\n",
    "train_dataset = GPT2Dataset(prompt_list_train, answer_list_train, tokenizer,\n",
    "               max_length_propmt=150, max_length_answer=6)\n",
    "val_dataset = GPT2Dataset(prompt_list_test, answer_list_test, tokenizer,\n",
    "               max_length_propmt=150, max_length_answer=6)\n",
    "\n",
    "\n",
    "print('{:>5,} training samples'.format(len(prompt_list_train)))\n",
    "print('{:>5,} validation samples'.format(len(prompt_list_test)))\n",
    "\n",
    "\n",
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "config_path = path\n",
    "model_path = path\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 5e-6\n",
    "warmup_ratio = 0.2\n",
    "epsilon = 1e-8\n",
    "\n",
    "model, tokenizer, training_stats = model_training(config_path, model_path, tokenizer,\n",
    "                                                   train_dataloader,validation_dataloader,\n",
    "                                                   epochs,learning_rate,warmup_ratio,\n",
    "                                                    epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /work/PolyGPT/T5/model_save/cls-T5-bs150-bs8-lr5e6-epoch100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/work/PolyGPT/T5/model_save/cls-T5-bs150-bs8-lr5e6-epoch100/tokenizer_config.json',\n",
       " '/work/PolyGPT/T5/model_save/cls-T5-bs150-bs8-lr5e6-epoch100/special_tokens_map.json',\n",
       " '/work/PolyGPT/T5/model_save/cls-T5-bs150-bs8-lr5e6-epoch100/spiece.model',\n",
       " '/work/PolyGPT/T5/model_save/cls-T5-bs150-bs8-lr5e6-epoch100/added_tokens.json',\n",
       " '/work/PolyGPT/T5/model_save/cls-T5-bs150-bs8-lr5e6-epoch100/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = '/work/PolyGPT/T5/model_save/cls-5tasks-bs150-bs8-lr5e6-epoch100'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32112, 411, 2423, 75, 536, 29, 599, 254, 61, 75, 599, 2423, 667, 61, 75, 357, 75, 75, 519, 75, 599, 2423, 667, 61, 29, 599, 18, 75, 591, 75, 75, 75, 599, 18, 75, 755, 75, 75, 75, 599, 254, 61, 75, 75, 9120, 75, 75, 7256, 75, 599, 2423, 667, 61, 75, 519, 75, 75, 2658, 1]\n",
      "['Predict the heat resistance class of the following SMILES:', '▁O', '=', 'c', '1', 'n', '(', 'C', ')', 'c', '(', '=', 'O', ')', 'c', '2', 'c', 'c', '3', 'c', '(', '=', 'O', ')', 'n', '(', '-', 'c', '4', 'c', 'c', 'c', '(', '-', 'c', '5', 'c', 'c', 'c', '(', 'C', ')', 'c', 'c', '5)', 'c', 'c', '4)', 'c', '(', '=', 'O', ')', 'c', '3', 'c', 'c', '21', '</s>']\n",
      "1: <pad><s> class 1</s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt = '[CLS]' + \"[*]NC(=O)OC(C=C1)=CC=C1[*]'s band gap chain is\"\n",
    "\n",
    "# prompt = \"N1(CCCCCCCCN2C(=O)c3cccc(*)c3C2=O)C(=O)c2c(c(Oc3ccc(Oc4ccc(O*)cc4)cc3)ccc2)C1=O\"\n",
    "prompt = 'Predict the heat resistance class of the following SMILES: O=c1n(C)c(=O)c2cc3c(=O)n(-c4ccc(-c5ccc(C)cc5)cc4)c(=O)c3cc21'\n",
    "\n",
    "generated = tokenizer.encode(prompt)\n",
    "print(generated)\n",
    "tokens = tokenizer.convert_ids_to_tokens(generated)\n",
    "print(tokens)\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generated = generated.to(device)\n",
    "\n",
    "sample_outputs = model.module.generate(\n",
    "                                generated, \n",
    "                                #bos_token_id=random.randint(1,30000),\n",
    "                                do_sample=False,   \n",
    "                                top_k=100, \n",
    "                                max_length = 8,\n",
    "                                top_p=0.99, \n",
    "                                num_return_sequences=1\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TransPolymer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
